{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb0ca6d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['peptide_sequences', 'precursor_charges', 'normalized_collision_energies']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import onnxruntime as ort\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import collections\n",
    "import functools\n",
    "\n",
    "session = ort.InferenceSession(\"models\\prosit\\hla_cid\\weight_192_0.16253_compatible.onnx\")\n",
    "input_names = [input.name for input in session.get_inputs()]\n",
    "input_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9fe403b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants from https://github.com/kusterlab/prosit/blob/master/prosit/constants.py\n",
    "DATA_PATH = \"/root/data.hdf5\"\n",
    "MODEL_SPECTRA = \"/root/model_spectra/\"\n",
    "MODEL_IRT = \"/root/model_irt/\"\n",
    "OUT_DIR = \"/root/prediction/\"\n",
    "\n",
    "VAL_SPLIT = 0.8\n",
    "\n",
    "TRAIN_EPOCHS = 500\n",
    "TRAIN_BATCH_SIZE = 1024\n",
    "PRED_BATCH_SIZE = 1024\n",
    "PRED_BAYES = False\n",
    "PRED_N = 100\n",
    "\n",
    "TOLERANCE_FTMS = 25\n",
    "TOLERANCE_ITMS = 0.35\n",
    "TOLERANCE_TRIPLETOF = 0.5\n",
    "\n",
    "TOLERANCE = {\"FTMS\": (25, \"ppm\"), \"ITMS\": (0.35, \"da\"), \"TripleTOF\": (50, \"ppm\")}\n",
    "\n",
    "\n",
    "ALPHABET = {\n",
    "    \"A\": 1,\n",
    "    \"C\": 2,\n",
    "    \"D\": 3,\n",
    "    \"E\": 4,\n",
    "    \"F\": 5,\n",
    "    \"G\": 6,\n",
    "    \"H\": 7,\n",
    "    \"I\": 8,\n",
    "    \"K\": 9,\n",
    "    \"L\": 10,\n",
    "    \"M\": 11,\n",
    "    \"N\": 12,\n",
    "    \"P\": 13,\n",
    "    \"Q\": 14,\n",
    "    \"R\": 15,\n",
    "    \"S\": 16,\n",
    "    \"T\": 17,\n",
    "    \"V\": 18,\n",
    "    \"W\": 19,\n",
    "    \"Y\": 20,\n",
    "    \"M(ox)\": 21,\n",
    "}\n",
    "ALPHABET_S = {integer: char for char, integer in ALPHABET.items()}\n",
    "\n",
    "CHARGES = [1, 2, 3, 4, 5, 6]\n",
    "DEFAULT_MAX_CHARGE = len(CHARGES)\n",
    "MAX_FRAG_CHARGE = 3\n",
    "MAX_SEQUENCE = 30\n",
    "MAX_ION = MAX_SEQUENCE - 1\n",
    "ION_TYPES = [\"y\", \"b\"]\n",
    "NLOSSES = [\"\", \"H2O\", \"NH3\"]\n",
    "\n",
    "FORWARD = {\"a\", \"b\", \"c\"}\n",
    "BACKWARD = {\"x\", \"y\", \"z\"}\n",
    "\n",
    "# Amino acids\n",
    "MODIFICATION = {\n",
    "    \"CAM\": 57.0214637236,  # Carbamidomethylation (CAM)\n",
    "    \"OX\": 15.99491,  # Oxidation\n",
    "}\n",
    "AMINO_ACID = {\n",
    "    \"G\": 57.021464,\n",
    "    \"R\": 156.101111,\n",
    "    \"V\": 99.068414,\n",
    "    \"P\": 97.052764,\n",
    "    \"S\": 87.032028,\n",
    "    \"U\": 150.95363,\n",
    "    \"L\": 113.084064,\n",
    "    \"M\": 131.040485,\n",
    "    \"Q\": 128.058578,\n",
    "    \"N\": 114.042927,\n",
    "    \"Y\": 163.063329,\n",
    "    \"E\": 129.042593,\n",
    "    \"C\": 103.009185 + MODIFICATION[\"CAM\"],\n",
    "    \"F\": 147.068414,\n",
    "    \"I\": 113.084064,\n",
    "    \"A\": 71.037114,\n",
    "    \"T\": 101.047679,\n",
    "    \"W\": 186.079313,\n",
    "    \"H\": 137.058912,\n",
    "    \"D\": 115.026943,\n",
    "    \"K\": 128.094963,\n",
    "}\n",
    "AMINO_ACID[\"M(ox)\"] = AMINO_ACID[\"M\"] + MODIFICATION[\"OX\"]\n",
    "\n",
    "# Atomic elements\n",
    "PROTON = 1.007276467\n",
    "ELECTRON = 0.00054858\n",
    "H = 1.007825035\n",
    "C = 12.0\n",
    "O = 15.99491463\n",
    "N = 14.003074\n",
    "\n",
    "# Tiny molecules\n",
    "N_TERMINUS = H\n",
    "C_TERMINUS = O + H\n",
    "CO = C + O\n",
    "CHO = C + H + O\n",
    "NH2 = N + H * 2\n",
    "H2O = H * 2 + O\n",
    "NH3 = N + H * 3\n",
    "\n",
    "NEUTRAL_LOSS = {\"NH3\": NH3, \"H2O\": H2O}\n",
    "\n",
    "ION_OFFSET = {\n",
    "    \"a\": N_TERMINUS - CHO,\n",
    "    \"b\": N_TERMINUS - H,\n",
    "    \"c\": N_TERMINUS + NH2,\n",
    "    \"x\": C_TERMINUS + CO - H,\n",
    "    \"y\": C_TERMINUS + H,\n",
    "    \"z\": C_TERMINUS - NH2,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a496136d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Annotations from https://github.com/kusterlab/prosit/blob/master/prosit/annotate.py\n",
    "\n",
    "def adjust_masses(method):\n",
    "    if method == \"SILAC\":\n",
    "        offsets = {\"K\": 8.01419881319, \"R\": 10.008268599}\n",
    "    else:\n",
    "        raise ValueError(\"Don't know method: \" + method)\n",
    "\n",
    "    for aa, offset in offsets.items():\n",
    "        AMINO_ACID[aa] += offset\n",
    "\n",
    "\n",
    "def get_mz(sum_, ion_offset, charge):\n",
    "    return (sum_ + ion_offset + charge * PROTON) / charge\n",
    "\n",
    "\n",
    "def get_mzs(cumsum, ion_type, z):\n",
    "    return [get_mz(s, ION_OFFSET[ion_type], z) for s in cumsum[:-1]]\n",
    "\n",
    "\n",
    "def get_annotation(forward, backward, charge, ion_types):\n",
    "    tmp = \"{}{}\"\n",
    "    tmp_nl = \"{}{}-{}\"\n",
    "    all_ = {}\n",
    "    for ion_type in ion_types:\n",
    "        if ion_type in FORWARD:\n",
    "            cummass = forward\n",
    "        elif ion_type in BACKWARD:\n",
    "            cummass = backward\n",
    "        else:\n",
    "            raise ValueError(\"unkown ion_type: {}\".format(ion_type))\n",
    "        masses = get_mzs(cummass, ion_type, charge)\n",
    "        d = {tmp.format(ion_type, i + 1): m for i, m in enumerate(masses)}\n",
    "        all_.update(d)\n",
    "        for nl, offset in NEUTRAL_LOSS.items():\n",
    "            nl_masses = get_mzs(cummass - offset, ion_type, charge)\n",
    "            d = {tmp_nl.format(ion_type, i + 1, nl): m for i, m in enumerate(nl_masses)}\n",
    "            all_.update(d)\n",
    "    return collections.OrderedDict(sorted(all_.items(), key=lambda t: t[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb4b2814",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utils from from https://github.com/kusterlab/prosit/blob/master/prosit/utils.py\n",
    "\n",
    "def check_mandatory_keys(dictionary, keys):\n",
    "    for key in keys:\n",
    "        if key not in dictionary.keys():\n",
    "            raise KeyError(\"key {} is missing\".format(key))\n",
    "    return True\n",
    "\n",
    "\n",
    "def reshape_dims(array, nlosses=1, z=3):\n",
    "    return array.reshape([array.shape[0], MAX_ION, len(ION_TYPES), nlosses, z])\n",
    "\n",
    "\n",
    "def get_sequence(sequence):\n",
    "    d = ALPHABET_S\n",
    "    return \"\".join([d[i] if i in d else \"\" for i in sequence])\n",
    "\n",
    "\n",
    "def sequence_integer_to_str(array):\n",
    "    sequences = [get_sequence(array[i]) for i in range(array.shape[0])]\n",
    "    return sequences\n",
    "\n",
    "\n",
    "def peptide_parser(p):\n",
    "    p = p.replace(\"_\", \"\")\n",
    "    if p[0] == \"(\":\n",
    "        raise ValueError(\"sequence starts with '('\")\n",
    "    n = len(p)\n",
    "    i = 0\n",
    "    while i < n:\n",
    "        if i < n - 3 and p[i + 1] == \"(\":\n",
    "            j = p[i + 2 :].index(\")\")\n",
    "            offset = i + j + 3\n",
    "            yield p[i:offset]\n",
    "            i = offset\n",
    "        else:\n",
    "            yield p[i]\n",
    "            i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9879fe42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity utils from https://github.com/kusterlab/prosit/blob/master/prosit/sanitize.py\n",
    "\n",
    "def reshape_dims(array):\n",
    "    n, dims = array.shape\n",
    "    assert dims == 174\n",
    "    nlosses = 1\n",
    "    return array.reshape(\n",
    "        [array.shape[0], MAX_SEQUENCE - 1, len(ION_TYPES), nlosses, MAX_FRAG_CHARGE]\n",
    "    )\n",
    "\n",
    "\n",
    "def reshape_flat(array):\n",
    "    s = array.shape\n",
    "    flat_dim = [s[0], functools.reduce(lambda x, y: x * y, s[1:], 1)]\n",
    "    return array.reshape(flat_dim)\n",
    "\n",
    "\n",
    "def normalize_base_peak(array):\n",
    "    # flat\n",
    "    maxima = array.max(axis=1)\n",
    "    array = array / maxima[:, numpy.newaxis]\n",
    "    return array\n",
    "\n",
    "\n",
    "def mask_outofrange(array, lengths, mask=-1.0):\n",
    "    # dim\n",
    "    for i in range(array.shape[0]):\n",
    "        array[i, lengths[i] - 1 :, :, :, :] = mask\n",
    "    return array\n",
    "\n",
    "\n",
    "def cap(array, nlosses=1, z=3):\n",
    "    return array[:, :, :, :nlosses, :z]\n",
    "\n",
    "\n",
    "def mask_outofcharge(array, charges, mask=-1.0):\n",
    "    # dim\n",
    "    for i in range(array.shape[0]):\n",
    "        if charges[i] < 3:\n",
    "            array[i, :, :, :, charges[i] :] = mask\n",
    "    return array\n",
    "\n",
    "\n",
    "def get_spectral_angle(true, pred, batch_size=600):\n",
    "    import tensorflow\n",
    "\n",
    "    n = true.shape[0]\n",
    "    sa = numpy.zeros([n])\n",
    "\n",
    "    def iterate():\n",
    "        if n > batch_size:\n",
    "            for i in range(n // batch_size):\n",
    "                true_sample = true[i * batch_size : (i + 1) * batch_size]\n",
    "                pred_sample = pred[i * batch_size : (i + 1) * batch_size]\n",
    "                yield i, true_sample, pred_sample\n",
    "            i = n // batch_size\n",
    "            yield i, true[(i) * batch_size :], pred[(i) * batch_size :]\n",
    "        else:\n",
    "            yield 0, true, pred\n",
    "\n",
    "    for i, t_b, p_b in iterate():\n",
    "        tensorflow.reset_default_graph()\n",
    "        with tensorflow.Session() as s:\n",
    "            sa_graph = losses.masked_spectral_distance(t_b, p_b)\n",
    "            sa_b = 1 - s.run(sa_graph)\n",
    "            sa[i * batch_size : i * batch_size + sa_b.shape[0]] = sa_b\n",
    "    sa = numpy.nan_to_num(sa)\n",
    "    return sa\n",
    "\n",
    "\n",
    "def prediction(data, batch_size=600):\n",
    "    assert \"sequence_integer\" in data\n",
    "    assert \"intensities_pred\" in data\n",
    "    assert \"precursor_charge_onehot\" in data\n",
    "\n",
    "    sequence_lengths = numpy.count_nonzero(data[\"sequence_integer\"], axis=1)\n",
    "    intensities = data[\"intensities_pred\"]\n",
    "    charges = list(data[\"precursor_charge_onehot\"].argmax(axis=1) + 1)\n",
    "\n",
    "    intensities[intensities < 0] = 0\n",
    "    intensities = normalize_base_peak(intensities)\n",
    "    intensities = reshape_dims(intensities)\n",
    "    intensities = mask_outofrange(intensities, sequence_lengths)\n",
    "    intensities = mask_outofcharge(intensities, charges)\n",
    "    intensities = reshape_flat(intensities)\n",
    "    data[\"intensities_pred\"] = intensities\n",
    "\n",
    "    if \"intensities_raw\" in data:\n",
    "        data[\"spectral_angle\"] = get_spectral_angle(\n",
    "            data[\"intensities_raw\"], data[\"intensities_pred\"], batch_size=batch_size\n",
    "        )\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8fe8ffb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Losses from https://github.com/kusterlab/prosit/blob/master/prosit/losses.py\n",
    "\n",
    "def masked_spectral_distance(true, pred):\n",
    "    # Note, fragment ions that cannot exists (i.e. y20 for a 7mer) must have the value  -1.\n",
    "    import tensorflow\n",
    "    import keras.backend as k\n",
    "\n",
    "    epsilon = k.epsilon()\n",
    "    pred_masked = ((true + 1) * pred) / (true + 1 + epsilon)\n",
    "    true_masked = ((true + 1) * true) / (true + 1 + epsilon)\n",
    "    pred_norm = k.l2_normalize(true_masked, axis=-1)\n",
    "    true_norm = k.l2_normalize(pred_masked, axis=-1)\n",
    "    product = k.sum(pred_norm * true_norm, axis=1)\n",
    "    arccos = tensorflow.acos(product)\n",
    "    return 2 * arccos / numpy.pi\n",
    "\n",
    "\n",
    "losses = {\"masked_spectral_distance\": masked_spectral_distance}\n",
    "\n",
    "\n",
    "def get(loss_name):\n",
    "    if loss_name in losses:\n",
    "        return losses[loss_name]\n",
    "    else:\n",
    "        return loss_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "36748033",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Match from https://github.com/kusterlab/prosit/blob/master/prosit/match.py\n",
    "\n",
    "def read_attribute(row, attribute):\n",
    "    if \" \" not in str(row[attribute]):\n",
    "        return []\n",
    "    else:\n",
    "        return [float(m) for m in row[attribute].split(\" \")]\n",
    "\n",
    "\n",
    "def peptide_parser(p):\n",
    "    if p[0] == \"(\":\n",
    "        raise ValueError(\"sequence starts with '('\")\n",
    "    n = len(p)\n",
    "    i = 0\n",
    "    while i < n:\n",
    "        if i < n - 3 and p[i + 1] == \"(\":\n",
    "            j = p[i + 2 :].index(\")\")\n",
    "            offset = i + j + 3\n",
    "            yield p[i:offset]\n",
    "            i = offset\n",
    "        else:\n",
    "            yield p[i]\n",
    "            i += 1\n",
    "\n",
    "\n",
    "def get_forward_backward(peptide):\n",
    "    amino_acids = peptide_parser(peptide)\n",
    "    masses = [AMINO_ACID[a] for a in amino_acids]\n",
    "    forward = np.cumsum(masses)\n",
    "    backward = np.cumsum(list(reversed(masses)))\n",
    "    return forward, backward\n",
    "\n",
    "\n",
    "def get_tolerance(theoretical, mass_analyzer):\n",
    "    if mass_analyzer in TOLERANCE:\n",
    "        tolerance, unit = TOLERANCE[mass_analyzer]\n",
    "        if unit == \"ppm\":\n",
    "            return theoretical * float(tolerance) / 10 ** 6\n",
    "        elif unit == \"da\":\n",
    "            return float(tolerance)\n",
    "        else:\n",
    "            raise ValueError(\"unit {} not implemented\".format(unit))\n",
    "    else:\n",
    "        raise ValueError(\"no tolerance implemented for {}\".format(mass_analyzer))\n",
    "\n",
    "\n",
    "def is_in_tolerance(theoretical, observed, mass_analyzer):\n",
    "    mz_tolerance = get_tolerance(theoretical, mass_analyzer)\n",
    "    lower = observed - mz_tolerance\n",
    "    upper = observed + mz_tolerance\n",
    "    return theoretical >= lower and theoretical <= upper\n",
    "\n",
    "\n",
    "def binarysearch(masses_raw, theoretical, mass_analyzer):\n",
    "    lo, hi = 0, len(masses_raw) - 1\n",
    "    while lo <= hi:\n",
    "        mid = (lo + hi) // 2\n",
    "        if is_in_tolerance(theoretical, masses_raw[mid], mass_analyzer):\n",
    "            return mid\n",
    "        elif masses_raw[mid] < theoretical:\n",
    "            lo = mid + 1\n",
    "        elif theoretical < masses_raw[mid]:\n",
    "            hi = mid - 1\n",
    "    return None\n",
    "\n",
    "\n",
    "def match(row, ion_types, max_charge=DEFAULT_MAX_CHARGE):\n",
    "    masses_observed = read_attribute(row, \"masses_raw\")\n",
    "    intensities_observed = read_attribute(row, \"intensities_raw\")\n",
    "    forward_sum, backward_sum = get_forward_backward(row.modified_sequence[1:-1])\n",
    "    _max_charge = row.charge if row.charge <= max_charge else max_charge\n",
    "    matches = []\n",
    "    for charge_index in range(_max_charge):\n",
    "        d = {\n",
    "            \"masses_raw\": [],\n",
    "            \"masses_theoretical\": [],\n",
    "            \"intensities_raw\": [],\n",
    "            \"matches\": [],\n",
    "        }\n",
    "        charge = charge_index + 1\n",
    "        annotations = get_annotation(\n",
    "            forward_sum, backward_sum, charge, ion_types\n",
    "        )\n",
    "        for annotation, mass_t in annotations.items():\n",
    "            index = binarysearch(masses_observed, mass_t, row.mass_analyzer)\n",
    "            if index is not None:\n",
    "                d[\"masses_raw\"].append(masses_observed[index])\n",
    "                d[\"intensities_raw\"].append(intensities_observed[index])\n",
    "                d[\"masses_theoretical\"].append(mass_t)\n",
    "                d[\"matches\"].append(annotation)\n",
    "        matches.append(d)\n",
    "    return matches\n",
    "\n",
    "\n",
    "def c_lambda(matches, charge, attr):\n",
    "    def mapping(i):\n",
    "        charge_index = int(charge - 1)\n",
    "        m = matches[i]\n",
    "        if charge_index < len(m):\n",
    "            try:\n",
    "                s = \";\".join(map(str, m[charge_index][attr]))\n",
    "            except:\n",
    "                raise ValueError(m[charge_index][attr])\n",
    "        else:\n",
    "            s = \"\"\n",
    "        return s\n",
    "\n",
    "    return mapping\n",
    "\n",
    "\n",
    "def augment(df, ion_types, charge_max):\n",
    "    matches = {}\n",
    "    for i, row in df.iterrows():\n",
    "        matches[i] = match(row, ion_types, charge_max)\n",
    "\n",
    "    # augment dataframe and write\n",
    "    for charge in range(1, charge_max + 1):\n",
    "        df[\"matches_charge{}\".format(charge)] = df.index.map(\n",
    "            c_lambda(matches, charge, \"matches\")\n",
    "        )\n",
    "        df[\"masses_the_charge{}\".format(charge)] = df.index.map(\n",
    "            c_lambda(matches, charge, \"masses_theoretical\")\n",
    "        )\n",
    "        df[\"masses_raw_charge{}\".format(charge)] = df.index.map(\n",
    "            c_lambda(matches, charge, \"masses_raw\")\n",
    "        )\n",
    "        df[\"intensities_raw_charge{}\".format(charge)] = df.index.map(\n",
    "            c_lambda(matches, charge, \"intensities_raw\")\n",
    "        )\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "edb56b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorization from https://github.com/kusterlab/prosit/blob/master/prosit/tensorize.py\n",
    "\n",
    "def stack(queue):\n",
    "    listed = collections.defaultdict(list)\n",
    "    for t in queue.values():\n",
    "        if t is not None:\n",
    "            for k, d in t.items():\n",
    "                listed[k].append(d)\n",
    "    stacked = {}\n",
    "    for k, d in listed.items():\n",
    "        if isinstance(d[0], list):\n",
    "            stacked[k] = [item for sublist in d for item in sublist]\n",
    "        else:\n",
    "            stacked[k] = np.vstack(d)\n",
    "    return stacked\n",
    "\n",
    "\n",
    "def get_numbers(vals, dtype=float):\n",
    "    a = np.array(vals).astype(dtype)\n",
    "    return a.reshape([len(vals), 1])\n",
    "\n",
    "\n",
    "def get_precursor_charge_onehot(charges):\n",
    "    array = np.zeros([len(charges), max(CHARGES)], dtype=int)\n",
    "    for i, precursor_charge in enumerate(charges):\n",
    "        array[i, precursor_charge - 1] = 1\n",
    "    return array\n",
    "\n",
    "\n",
    "def get_sequence_integer(sequences):\n",
    "    array = np.zeros([len(sequences), MAX_SEQUENCE], dtype=int)\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        for j, s in enumerate(peptide_parser(sequence)):\n",
    "            array[i, j] = ALPHABET[s]\n",
    "    return array\n",
    "\n",
    "\n",
    "def parse_ion(string):\n",
    "    ion_type = ION_TYPES.index(string[0])\n",
    "    if (\"-\") in string:\n",
    "        ion_n, suffix = string[1:].split(\"-\")\n",
    "    else:\n",
    "        ion_n = string[1:]\n",
    "        suffix = \"\"\n",
    "    return ion_type, int(ion_n) - 1, NLOSSES.index(suffix)\n",
    "\n",
    "\n",
    "def get_mz_applied(df, ion_types=\"yb\"):\n",
    "    ito = {it: ION_OFFSET[it] for it in ion_types}\n",
    "\n",
    "    def calc_row(row):\n",
    "        array = np.zeros([MAX_ION, len(ION_TYPES), len(NLOSSES), len(CHARGES)])\n",
    "        fw, bw = get_forward_backward(row.modified_sequence)\n",
    "        for z in range(row.precursor_charge):\n",
    "            zpp = z + 1\n",
    "            annotation = get_annotation(fw, bw, zpp, ito)\n",
    "            for ion, mz in annotation.items():\n",
    "                it, _in, nloss = parse_ion(ion)\n",
    "                array[_in, it, nloss, z] = mz\n",
    "        return [array]\n",
    "\n",
    "    mzs_series = df.apply(calc_row, 1)\n",
    "    out = np.squeeze(np.stack(mzs_series))\n",
    "    if len(out.shape) == 4:\n",
    "        out = out.reshape([1] + list(out.shape))\n",
    "    return out\n",
    "\n",
    "\n",
    "def csv(df):\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    assert \"modified_sequence\" in df.columns\n",
    "    assert \"collision_energy\" in df.columns\n",
    "    assert \"precursor_charge\" in df.columns\n",
    "    data = {\n",
    "        \"collision_energy_aligned_normed\": get_numbers(df.collision_energy) / 100.0,\n",
    "        \"sequence_integer\": get_sequence_integer(df.modified_sequence),\n",
    "        \"precursor_charge_onehot\": get_precursor_charge_onehot(df.precursor_charge),\n",
    "        \"masses_pred\": get_mz_applied(df),\n",
    "    }\n",
    "    nlosses = 1\n",
    "    z = 3\n",
    "    lengths = (data[\"sequence_integer\"] > 0).sum(1)\n",
    "\n",
    "    masses_pred = get_mz_applied(df)\n",
    "    masses_pred = cap(masses_pred, nlosses, z)\n",
    "    masses_pred = mask_outofrange(masses_pred, lengths)\n",
    "    masses_pred = mask_outofcharge(masses_pred, df.precursor_charge)\n",
    "    masses_pred = reshape_flat(masses_pred)\n",
    "    data[\"masses_pred\"] = masses_pred\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "918a773d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.DataFrame({\n",
    "    \"modified_sequence\": [\"ACDEFGHIK\", \"LM(ox)NPQRSTV\"],\n",
    "    \"collision_energy\": [30, 35],\n",
    "    \"precursor_charge\": [2, 3],\n",
    "})\n",
    "\n",
    "data = csv(test_df)\n",
    "inputs = dict()\n",
    "inputs['peptide_sequences'] = data['sequence_integer'].astype(np.float32)\n",
    "inputs['precursor_charges'] = data['precursor_charge_onehot'].astype(np.float32)\n",
    "inputs['normalized_collision_energies'] = data['collision_energy_aligned_normed'].astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "451d8416",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = session.run(None, inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b638a25a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 174)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df9d771",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prosit2csharp (3.11.14)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
